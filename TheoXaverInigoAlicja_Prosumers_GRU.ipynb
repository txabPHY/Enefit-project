{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date, timedelta\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "data= pd.read_csv('/Users/theobeevers/AppliedMachineLearning2024/final poject/all_data/train_full.csv')\n",
    "\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['weekday'] = data['datetime'].dt.weekday\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data.sort_values(by='datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_company_data = data[data['prediction_unit_id'] == 1]\n",
    "\n",
    "production_data = one_company_data[one_company_data['is_consumption'] == 0]\n",
    "\n",
    "hold = production_data[['target', 'installed_capacity']].copy()\n",
    "\n",
    "production_data['target'] = production_data['target']/production_data['installed_capacity']\n",
    "production_data.drop(['installed_capacity'], axis=1, inplace=True)\n",
    "\n",
    "consumption_data  = one_company_data[one_company_data['is_consumption'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_features = ['county', 'product_type', 'hour', 'month', 'weekday', 'day', 'is_business']\n",
    "numerical_features = production_data.columns.difference(categorical_features + ['target','datetime'])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "data_preprocessed = preprocessor.fit_transform(production_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, sequence_length=24):\n",
    "    X_seqs, y_seqs = [], []\n",
    "    # Ensure the loop does not go beyond the point where a valid target exists\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seqs.append(X[i:i + sequence_length])\n",
    "        y_seqs.append(y[i + sequence_length])\n",
    "    return np.array(X_seqs), np.array(y_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data_preprocessed \n",
    "data_targets = production_data['target'].values \n",
    "\n",
    "dates = production_data['datetime'].values \n",
    "\n",
    "split_idx = int(len(dates) * 0.5)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = data_features[:split_idx]\n",
    "y_train = data_targets[:split_idx]\n",
    "X_test = data_features[split_idx:]\n",
    "y_test = data_targets[split_idx:]\n",
    "\n",
    "# Create sequences for training and testing sets\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(dates[:split_idx], y_train, label='Training Data', color='blue')\n",
    "plt.plot(dates[split_idx:], y_test, label='Testing Data', color='red', linestyle='--')\n",
    "\n",
    "# Highlight the transition from training to testing\n",
    "plt.axvline(x=dates[split_idx], color='gray', linestyle='--', label='Start of Test Data')\n",
    "\n",
    "# Formatting the date on the x-axis for better readability\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gcf().autofmt_xdate()  # Rotation\n",
    "\n",
    "plt.title('Training and Testing Data Split')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Production')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq = y_train_seq.reshape(-1, 1)  \n",
    "y_test_seq = y_test_seq.reshape(-1,1)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_test_seq, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, 50, 2, batch_first=True)  # 50 hidden units, 2 layers\n",
    "        self.fc = nn.Linear(50, 1)  # Predicting one output per time step\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.fc(x)\n",
    "        x = x[:, -1, :]\n",
    "        # Select only the last timestep for each sequence\n",
    "        return x.unsqueeze(-1)\n",
    "\n",
    "input_dim = X_train_tensor.shape[2]  # This is the number of features per time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = GRUNet(input_dim)  # Ensure the input_dim is correctly set\n",
    "criterion = nn.L1Loss()  # L1 Loss function for MAE\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Make sure your data tensors are also moved to the same device\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "y_val_tensor = y_val_tensor.to(device)\n",
    "\n",
    "# Cast tensors to float16\n",
    "# Ensure everything is in float16\n",
    "# model = model.half()  # Convert model to float16\n",
    "# X_train_tensor = X_train_tensor.half()\n",
    "# y_train_tensor = y_train_tensor.half()\n",
    "# X_val_tensor = X_val_tensor.half()\n",
    "# y_val_tensor = y_val_tensor.half()\n",
    "\n",
    "num_epochs = 50 # Define the number of epochs\n",
    "# print(\"Check NaN or Inf in inputs:\", torch.isnan(X_train_tensor).any(), torch.isinf(X_train_tensor).any())\n",
    "# print(\"Check NaN or Inf in targets:\", torch.isnan(y_train_tensor).any(), torch.isinf(y_train_tensor).any())\n",
    "\n",
    "# print(\"Check NaN or Inf in inputs:\", torch.isnan(X_val_tensor).any(), torch.isinf(X_val_tensor).any())\n",
    "# print(\"Check NaN or Inf in targets:\", torch.isnan(y_val_tensor).any(, torch.isinf(y_val_tensor).any())\n",
    "\n",
    "\n",
    "# Check for NaNs in each feature\n",
    "# nan_counts = pd.DataFrame(torch.isnan(X_train_tensor).sum(dim=0))\n",
    "# print(\"NaN counts per feature:\", nan_counts)\n",
    "# nan_counts.to_csv('nan_counts')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    outputs = outputs.squeeze(-1)\n",
    "\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    if not torch.isfinite(loss):\n",
    "        print(f\"Stopping training, loss has become {loss.item()}\")\n",
    "        break  # Early exit if loss is nan or inf\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {loss.item()}')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_outputs = val_outputs.squeeze(-1)  # Ensure validation output matches target shape\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "    # Existing training and validation code...\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)  # Ensure data is on the correct device\n",
    "    predicted_output = model(X_test_tensor)\n",
    "    predicted_output = predicted_output.cpu().numpy().flatten()  # Move predictions back to CPU and flatten if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates = production_data['datetime'].values  # Ensure correct format\n",
    "sequence_length = 24 \n",
    "\n",
    "split_idx = int(len(dates) * 0.5)\n",
    "# Prediction starts after the first 'sequence_length' entries in the test set\n",
    "prediction_start_idx = split_idx + sequence_length\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(dates[:split_idx], y_train, label='Training Data', color='blue')\n",
    "plt.plot(dates[split_idx:], y_test, label='Actual Test Data', color='red')\n",
    "plt.plot(dates[prediction_start_idx:], predicted_output, label='Predicted Data', color='green', linestyle='--')\n",
    "\n",
    "plt.axvline(x=dates[split_idx], color='gray', linestyle='--', label='Start of Test Data')\n",
    "\n",
    "# Formatting the date on the x-axis for better readability\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gcf().autofmt_xdate()  # Rotation\n",
    "\n",
    "plt.title('Training, Actual Test data, and Predicted Data on raw target values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Production')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = hold['installed_capacity'][prediction_start_idx:] * predicted_output\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(dates[split_idx:], hold['target'][split_idx:], label='Actual Test Data', color='red')\n",
    "plt.plot(dates[prediction_start_idx:], original, label='Predicted Data', color='green', linestyle='--')\n",
    "plt.axvline(x=dates[split_idx], color='gray', linestyle='--', label='Start of Test Data')\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title('Predicted Data on original target values when multiplied back to original scale')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Production')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaled_predictions = hold['installed_capacity'][prediction_start_idx:] * predicted_output\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(dates[split_idx:], hold['target'][split_idx:], label='Actual Test Data', color='red')\n",
    "plt.plot(dates[prediction_start_idx:], scaled_predictions, label='Scaled Predicted Data', color='green', linestyle='--')\n",
    "\n",
    "plt.axvline(x=dates[split_idx], color='gray', linestyle='--', label='Start of Test Data')\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gcf().autofmt_xdate()  # Rotate date labels for better readability\n",
    "\n",
    "plt.title('Comparison of Actual Test Data and Scaled Predicted Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Production')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled_predictions = np.empty_like(hold['target'])\n",
    "full_scaled_predictions[:] = np.nan  # Initialize with NaNs\n",
    "full_scaled_predictions[prediction_start_idx:] = hold['installed_capacity'][prediction_start_idx:] * predicted_output\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(dates[:split_idx], hold['target'][:split_idx], label='Training Data', color='blue')\n",
    "plt.plot(dates[split_idx:], hold['target'][split_idx:], label='Actual Test Data', color='red')\n",
    "\n",
    "plt.plot(dates, full_scaled_predictions, label='Scaled Predicted Data', color='green', linestyle='--')\n",
    "plt.axvline(x=dates[split_idx], color='gray', linestyle='--', label='Start of Test Data')\n",
    "\n",
    "# Format the date on the x-axis for better readability\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gcf().autofmt_xdate()  # Rotate date labels for better readability\n",
    "\n",
    "plt.title('Full Timeline: Actual vs. Scaled Predicted Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Production')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_values = hold['target'][prediction_start_idx:]\n",
    "\n",
    "mae = mean_absolute_error(actual_test_values, scaled_predictions)\n",
    "print(f\"Mean Absolute Error for scaled predictions: {mae}\")\n",
    "\n",
    "mae = mean_absolute_error(y_test, predicted_output)\n",
    "print(f\"Mean Absolute Error for normalised predictions: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appliedmachinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
